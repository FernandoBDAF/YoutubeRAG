# Implementation Strategy Guide: Stage Domain Refactor

**Type**: Planning Guide  
**Created**: 2025-11-15  
**Purpose**: Tactical guide for executing STAGE-DOMAIN-REFACTOR achievements with maximum efficiency and minimum risk  
**Audience**: Executors implementing the refactor  
**Status**: ‚úÖ Complete

---

## üìã Quick Start

If you're starting work on STAGE-DOMAIN-REFACTOR right now:

1. **Read this section first** (5 minutes)
2. **Pick your starting achievement** (see Priority Matrix below)
3. **Follow the execution workflow** (see Your First Hour section)
4. **Use the tactical checklists** (see Implementation Tactics section)

**Time to productivity**: <1 hour from starting to first meaningful work

---

## üéØ Execution Principles

### Principle 1: Test-First Always

**Every achievement follows TDD**:
```
1. Write tests that fail (define expected behavior)
2. Implement minimal code to pass tests
3. Refactor for quality
4. Repeat
```

**Why**: Validation phase found 9 bugs. Tests prevent regression.

**How to apply**:
- Before writing any production code, write the test
- Run test (should fail initially)
- Implement code to make test pass
- Run test again (should pass now)
- Refactor while keeping tests green

### Principle 2: Parallel Implementation (Strangler Fig)

**Never break existing code**:
```
1. Implement new pattern alongside old
2. Run both in parallel (validate equivalence)
3. Switch to new pattern (use feature flags)
4. Remove old pattern after soak period
```

**Why**: Zero downtime, easy rollback, gradual migration

**How to apply**:
- Create `ClassNameV2` or `new_function_name` 
- Keep old code working
- Use feature flags to control which version runs
- Compare outputs of both versions
- Migrate when confident

### Principle 3: Type-Safety First

**Every new code must have types**:
```python
# ‚úÖ GOOD: Fully typed
def process_entity(
    entity_id: str,
    confidence: float
) -> Optional[EntityDocument]:
    """Process entity and return document or None."""
    pass

# ‚ùå BAD: No types
def process_entity(entity_id, confidence):
    pass
```

**Why**: 33% of validation bugs would have been caught by type checking

**How to apply**:
- Add type hints to all new functions
- Define TypedDict for database documents
- Use Optional[] for nullable values
- Run `mypy --strict` before committing

### Principle 4: Extract, Don't Rewrite

**Refactor by extraction, not rewrite**:
```
1. Identify duplicated pattern
2. Extract to helper/base class
3. Replace duplicates with calls to extracted code
4. Test each replacement individually
```

**Why**: Preserves behavior, reduces risk, easier to review

**How to apply**:
- Find repeated code across stages
- Extract to GraphRAGBaseStage or helper
- Replace one usage at a time
- Test after each replacement

### Principle 5: Small PRs, Frequent Merges

**Keep changes small and merged quickly**:
```
Small PR (1-2 files, <500 lines):
- Easier to review
- Faster to merge
- Lower risk

vs

Big PR (10+ files, 2000+ lines):
- Hard to review
- Merge conflicts
- High risk
```

**Why**: Validation work showed small iterations find issues faster

**How to apply**:
- One achievement = one SUBPLAN = one PR (usually)
- Break large achievements into multiple iterations
- Merge to feature branch frequently
- Deploy to production incrementally

---

## üó∫Ô∏è Priority Matrix: Where to Start

### Tier 1: Foundation (Must Do First)

These achievements create the foundation for everything else. **Start here**.

| Achievement | Time | Impact | Dependencies | Start Priority |
|------------|------|--------|--------------|---------------|
| **0.1: GraphRAGBaseStage** | 3h | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | None | 1st - START HERE |
| **0.2: Query Helpers** | 2h | ‚≠ê‚≠ê‚≠ê | None | 2nd |
| **1.1: BaseStage Types** | 4h | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 0.1 | 3rd |

**Why These First**:
- 0.1 creates the base class all others inherit from
- 0.2 reduces query duplication immediately
- 1.1 adds types that catch bugs at dev time

**Estimated Total**: 9 hours  
**Prevents**: Decorator bugs, type errors, query duplication

### Tier 2: Critical Libraries (Do Next)

These prevent most validation bugs. **High priority**.

| Achievement | Time | Impact | Dependencies | Start Priority |
|------------|------|--------|--------------|---------------|
| **2.1: Retry Library** | 3h | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 0.1 | 4th - Prevents Bug #1 |
| **2.2: Validation Library** | 2h | ‚≠ê‚≠ê‚≠ê‚≠ê | 0.1 | 5th |
| **3.1: DatabaseContext** | 5h | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 1.1 | 6th - Prevents Bugs #2-4 |
| **1.2-1.3: Type Annotations** | 8h | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 1.1 | 7th - Prevents Bug #3 |

**Why These Next**:
- 2.1 standardizes retry patterns (prevents decorator errors)
- 3.1 extracts database operations (prevents race conditions)
- 1.2-1.3 complete type coverage (prevents attribute errors)

**Estimated Total**: 18 hours  
**Prevents**: 7 out of 9 validation bugs (78%)

### Tier 3: Architecture (Do After Foundation)

These improve architecture quality. **Medium priority**.

| Achievement | Time | Impact | Dependencies | Start Priority |
|------------|------|--------|--------------|---------------|
| **3.2: StageMetrics** | 3h | ‚≠ê‚≠ê‚≠ê‚≠ê | 0.1 | 8th |
| **3.3: BaseStage w/ DI** | 4h | ‚≠ê‚≠ê‚≠ê‚≠ê | 3.1, 3.2 | 9th |
| **4.1-4.3: Orchestration** | 12h | ‚≠ê‚≠ê‚≠ê‚≠ê | 3.3 | 10th |

**Estimated Total**: 19 hours  
**Benefits**: Clean architecture, easier testing, better separation

### Tier 4: Advanced (Do Last)

These are nice-to-have improvements. **Lower priority**.

| Achievement | Time | Impact | Dependencies | Start Priority |
|------------|------|--------|--------------|---------------|
| **5.1-5.3: DI Infrastructure** | 15h | ‚≠ê‚≠ê‚≠ê‚≠ê | 3.3 | 11th |
| **6.1-6.2: Feature Flags** | 6h | ‚≠ê‚≠ê‚≠ê | 5.3 | 12th |
| **2.3-2.6: Other Libraries** | 16h | ‚≠ê‚≠ê‚≠ê | Various | 13th |

**Estimated Total**: 37 hours  
**Benefits**: Better testing, dynamic configuration, more libraries

### Parallel Execution Opportunities

**Can run in parallel** (75% of achievements):

**Track A** (Foundation + Types):
```
0.1 ‚Üí 0.2 ‚Üí 1.1 ‚Üí 1.2 ‚Üí 1.3
Total: ~17 hours
```

**Track B** (Libraries):
```
[Wait for 0.1] ‚Üí 2.1 ‚Üí 2.2 ‚Üí 2.3 ‚Üí 2.4 ‚Üí 2.5 ‚Üí 2.6
Total: ~18 hours
```

**Track C** (Architecture):
```
[Wait for 1.1] ‚Üí 3.1 ‚Üí 3.2 ‚Üí 3.3 ‚Üí 4.1 ‚Üí 4.2 ‚Üí 4.3
Total: ~24 hours
```

**Execution Strategy**:
- Single executor: 67-82 hours sequential
- Two executors: 35-42 hours (Track A+B parallel, then C)
- Three executors: 24-30 hours (all tracks parallel)

**Time Savings**: 56-57% with parallel execution

---

## ‚è±Ô∏è Your First Hour: Tactical Steps

### Minutes 0-15: Context Loading

1. **Read key documents** (10 min):
   - EXECUTION_ANALYSIS_VALIDATION-LEARNINGS-SYNTHESIS.md (this folder)
   - EXECUTION_CASE-STUDY_OBSERVABILITY-VALIDATION-LEARNINGS.md (knowledge base)
   - The specific achievement you're implementing (in PLAN)

2. **Understand the why** (5 min):
   - What bug does this prevent?
   - What pattern does this establish?
   - How does it help the next plan?

### Minutes 15-30: Environment Setup

1. **Create your branch** (2 min):
```bash
cd /Users/fernandobarroso/repo/KnowledgeManager/GraphRAG
git checkout -b refactor/achievement-0.1-base-stage
```

2. **Set up testing** (3 min):
```bash
# Ensure pytest and mypy are installed
pip install -e .
pytest --version
mypy --version
```

3. **Create SUBPLAN** (10 min):
```bash
# Use SUBPLAN template
cp LLM/templates/SUBPLAN-TEMPLATE.md \
   work-space/plans/STAGE-DOMAIN-REFACTOR/subplans/SUBPLAN_STAGE-DOMAIN-REFACTOR_01.md

# Edit SUBPLAN with your specific approach
```

### Minutes 30-45: Test Creation (TDD Step 1)

1. **Create test file** (5 min):
```bash
touch tests/core/base/test_graphrag_base_stage.py
```

2. **Write first failing test** (10 min):
```python
# tests/core/base/test_graphrag_base_stage.py
import pytest
from core.base.graphrag_base_stage import GraphRAGBaseStage

def test_graphrag_base_stage_exists():
    """Test that GraphRAGBaseStage can be imported."""
    assert GraphRAGBaseStage is not None

def test_graphrag_base_stage_has_setup_method():
    """Test that GraphRAGBaseStage has setup method."""
    assert hasattr(GraphRAGBaseStage, 'setup')

# Run and watch it fail
# pytest tests/core/base/test_graphrag_base_stage.py
```

### Minutes 45-60: First Implementation

1. **Create minimal implementation** (10 min):
```python
# core/base/graphrag_base_stage.py
from typing import Optional
from core.base.stage import BaseStage

class GraphRAGBaseStage(BaseStage):
    """Base stage for all GraphRAG pipeline stages."""
    
    def setup(self) -> None:
        """Setup stage (override in subclass)."""
        pass
```

2. **Run tests** (2 min):
```bash
pytest tests/core/base/test_graphrag_base_stage.py -v
# Should pass now!
```

3. **Create EXECUTION_TASK** (3 min):
```bash
cp LLM/templates/EXECUTION_TASK-TEMPLATE.md \
   work-space/execution/EXECUTION_TASK_STAGE-DOMAIN-REFACTOR_01_01.md
```

**After First Hour**: You have:
- ‚úÖ Context loaded
- ‚úÖ Environment set up
- ‚úÖ SUBPLAN created
- ‚úÖ First test written and passing
- ‚úÖ EXECUTION_TASK started
- ‚úÖ Ready for serious implementation

---

## üõ†Ô∏è Implementation Tactics: Achievement-Specific

### Tactic 1: Implementing GraphRAGBaseStage (Achievement 0.1)

**Goal**: Extract common patterns from 4 stages into base class

**Step-by-Step**:

1. **Identify common patterns** (30 min):
```bash
# Look at all 4 stage files
code business/stages/graphrag/entity_extraction.py
code business/stages/graphrag/entity_resolution.py
code business/stages/graphrag/graph_construction.py
code business/stages/graphrag/community_detection.py

# Find duplicated code (setup, LLM client, collections)
```

2. **Create base class with common methods** (1 hour):
```python
# core/base/graphrag_base_stage.py
from typing import Optional, Dict, Any
from pymongo.database import Database
from core.base.stage import BaseStage
from business.services.llm.client import LLMClient

class GraphRAGBaseStage(BaseStage):
    """Base stage for GraphRAG pipeline stages.
    
    Provides common functionality:
    - LLM client setup
    - Collection access
    - Observability setup
    - Standard error handling
    """
    
    def __init__(self, db: Database, config: Dict[str, Any]):
        super().__init__(db, config)
        self.llm_client: Optional[LLMClient] = None
    
    def _setup_llm_client(self) -> None:
        """Setup LLM client (common pattern across stages)."""
        from dependencies.llm.client import get_llm_client
        self.llm_client = get_llm_client()
    
    def _get_collection(self, name: str):
        """Get MongoDB collection by name."""
        return self.db[name]
    
    def _setup_observability(self) -> None:
        """Setup observability (transformation logging, metrics)."""
        # Common observability setup
        pass
```

3. **Migrate one stage at a time** (30 min each = 2 hours):
```python
# BEFORE (business/stages/graphrag/entity_extraction.py)
class EntityExtractionStage(BaseStage):
    def setup(self):
        # Setup LLM client
        from dependencies.llm.client import get_llm_client
        self.llm_client = get_llm_client()
        
        # Get collections
        self.chunks_collection = self.db["chunks"]
        self.entities_collection = self.db["entities_raw"]
        
        # Setup observability
        # ... lots of code ...

# AFTER
class EntityExtractionStage(GraphRAGBaseStage):
    def setup(self):
        self._setup_llm_client()  # From base class!
        self.chunks_collection = self._get_collection("chunks")
        self.entities_collection = self._get_collection("entities_raw")
        self._setup_observability()  # From base class!
```

4. **Test each migration** (15 min each):
```python
# tests/stages/graphrag/test_entity_extraction.py
def test_entity_extraction_inherits_from_graphrag_base():
    """Test EntityExtractionStage inherits from GraphRAGBaseStage."""
    assert issubclass(EntityExtractionStage, GraphRAGBaseStage)

def test_entity_extraction_setup_works():
    """Test setup method works after migration."""
    stage = EntityExtractionStage(db, config)
    stage.setup()
    assert stage.llm_client is not None
    assert stage.chunks_collection is not None
```

**Total Time**: ~3 hours  
**Lines Saved**: ~100 lines per stage (400 ‚Üí 100, -75%)

### Tactic 2: Adding Type Annotations (Achievements 1.1-1.3)

**Goal**: Add comprehensive type hints to catch bugs at dev time

**Step-by-Step**:

1. **Define database document schemas** (1 hour):
```python
# core/models/graphrag_types.py
from typing import TypedDict, Optional, List

class EntityDocument(TypedDict):
    """Schema for entity documents in entities_raw collection."""
    entity_id: str
    entity_type: str
    entity_name: str
    chunk_id: str
    video_id: str
    confidence: float
    source_text: str
    created_at: str

class ResolvedEntityDocument(TypedDict):
    """Schema for resolved entity documents."""
    entity_id: str
    original_ids: List[str]
    entity_type: str
    entity_name: str
    confidence: float
    merge_count: int
    resolved_at: str
```

2. **Type all function signatures** (2 hours):
```python
# BEFORE
def get_entity(entity_id):
    result = self.collection.find_one({"entity_id": entity_id})
    return result

# AFTER
def get_entity(
    self,
    entity_id: str
) -> Optional[EntityDocument]:
    """Get entity by ID.
    
    Args:
        entity_id: Entity ID to look up
        
    Returns:
        EntityDocument if found, None otherwise
    """
    result = self.collection.find_one({"entity_id": entity_id})
    return result  # Type checker knows this could be None!
```

3. **Add type hints to class attributes** (1 hour):
```python
# BEFORE
class EntityResolutionStage(GraphRAGBaseStage):
    def setup(self):
        self.entities_collection = self._get_collection("entities_raw")
        self.similarity_threshold = 0.85

# AFTER
from pymongo.collection import Collection

class EntityResolutionStage(GraphRAGBaseStage):
    entities_collection: Collection
    similarity_threshold: float
    
    def setup(self) -> None:
        self.entities_collection = self._get_collection("entities_raw")
        self.similarity_threshold = 0.85
```

4. **Run mypy and fix issues** (4 hours):
```bash
# Run mypy in strict mode
mypy --strict business/stages/graphrag/

# Fix all type errors
# Common fixes:
# - Add Optional[] for nullable values
# - Define proper return types
# - Handle None cases explicitly
```

**Total Time**: ~8 hours  
**Bug Prevention**: 33% of validation bugs

### Tactic 3: Integrating Retry Library (Achievement 2.1)

**Goal**: Standardize retry patterns to prevent decorator bugs

**Step-by-Step**:

1. **Review existing retry library** (30 min):
```bash
# Check if retry library exists
ls core/libraries/retry.py

# Read implementation
code core/libraries/retry.py
```

2. **Design decorator interface** (30 min):
```python
# core/libraries/retry.py
from typing import Callable, TypeVar, Any
from functools import wraps

T = TypeVar('T')

def with_retry(
    max_attempts: int = 3,
    backoff: str = "exponential",
    exceptions: tuple = (Exception,)
) -> Callable[[Callable[..., T]], Callable[..., T]]:
    """Retry decorator for LLM calls.
    
    Args:
        max_attempts: Maximum number of retry attempts
        backoff: Backoff strategy ("exponential" or "linear")
        exceptions: Tuple of exceptions to catch and retry
    
    Returns:
        Decorated function that retries on failure
    """
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> T:
            # Retry logic
            pass
        return wrapper
    return decorator
```

3. **Integrate into GraphRAGBaseStage** (1 hour):
```python
# core/base/graphrag_base_stage.py
from core.libraries.retry import with_retry

class GraphRAGBaseStage(BaseStage):
    @with_retry(max_attempts=3, backoff="exponential")
    def _call_llm(self, prompt: str) -> str:
        """Call LLM with automatic retry on failure."""
        if self.llm_client is None:
            raise ValueError("LLM client not initialized")
        return self.llm_client.call(prompt)
```

4. **Migrate all LLM calls** (1 hour):
```python
# BEFORE (business/stages/graphrag/entity_extraction.py)
def extract_entities(self, chunk_text):
    try:
        response = self.llm_client.call(prompt)
    except Exception as e:
        # Manual retry logic
        for attempt in range(3):
            try:
                response = self.llm_client.call(prompt)
                break
            except:
                if attempt == 2:
                    raise

# AFTER
def extract_entities(self, chunk_text):
    response = self._call_llm(prompt)  # Retry built-in!
```

**Total Time**: ~3 hours  
**Bug Prevention**: Decorator syntax errors (Bug #1)

### Tactic 4: Extracting DatabaseContext (Achievement 3.1)

**Goal**: Abstract database operations to prevent race conditions

**Step-by-Step**:

1. **Identify database patterns** (1 hour):
```bash
# Find all database operations
grep -r "update_one" business/stages/graphrag/
grep -r "insert_one" business/stages/graphrag/
grep -r "find" business/stages/graphrag/

# Document common patterns:
# - Entity upsert (with conflict handling)
# - Batch insert
# - Query with pagination
```

2. **Design DatabaseContext interface** (1 hour):
```python
# business/services/graphrag/database_context.py
from typing import Optional, List, Dict, Any
from pymongo.database import Database
from core.models.graphrag_types import EntityDocument

class DatabaseContext:
    """Database operations abstraction for GraphRAG stages.
    
    Handles:
    - Race condition prevention
    - Batching for performance
    - Common query patterns
    - Transaction support
    """
    
    def __init__(self, db: Database, batch_size: int = 100):
        self.db = db
        self.batch_size = batch_size
        self._write_buffer: Dict[str, List[Dict]] = {}
    
    def upsert_entity_mention(
        self,
        entity: EntityDocument,
        increment_count: bool = True
    ) -> None:
        """Upsert entity mention with proper conflict handling.
        
        Handles race conditions correctly:
        - Uses atomic $inc operations
        - Separates $setOnInsert from $inc fields
        - No read-modify-write patterns
        """
        # Tested implementation
        pass
    
    def batch_insert(
        self,
        collection_name: str,
        documents: List[Dict[str, Any]]
    ) -> None:
        """Batch insert documents with automatic batching."""
        # Performance-optimized batching
        pass
```

3. **Migrate database operations** (2 hours):
```python
# BEFORE (complex, error-prone)
entity_doc = {
    "$setOnInsert": {
        "entity_id": entity.entity_id,
        "source_count": 1,  # ‚ùå Conflicts with $inc!
    },
    "$inc": {"source_count": 1},
}
self.collection.update_one(filter, entity_doc, upsert=True)

# AFTER (simple, safe)
self.db_context.upsert_entity_mention(
    entity=entity,
    increment_count=True
)  # Handles conflicts correctly!
```

4. **Test concurrent scenarios** (1 hour):
```python
# tests/services/graphrag/test_database_context.py
def test_concurrent_entity_upserts():
    """Test race condition handling."""
    import threading
    
    def upsert_entity():
        db_context.upsert_entity_mention(entity)
    
    # Simulate concurrent writes
    threads = [threading.Thread(target=upsert_entity) for _ in range(10)]
    for t in threads: t.start()
    for t in threads: t.join()
    
    # Verify count is correct (not lost updates)
    entity_doc = db.entities.find_one({"entity_id": entity.entity_id})
    assert entity_doc["source_count"] == 10  # Atomic operations work!
```

**Total Time**: ~5 hours  
**Bug Prevention**: Database race conditions (Bugs #2-4)

---

## ‚úÖ Quality Gates: When to Merge

Use these checklists before merging any achievement:

### Code Quality Gates

- [ ] All new code has type annotations
- [ ] mypy --strict passes with no errors
- [ ] No `# type: ignore` comments added
- [ ] Code duplication reduced (not increased)
- [ ] Follows established patterns

### Testing Gates

- [ ] All new code has unit tests
- [ ] Test coverage >80% for new code
- [ ] All existing tests still pass
- [ ] Integration tests pass
- [ ] Concurrent scenarios tested (if database code)

### Documentation Gates

- [ ] Docstrings added to all public methods
- [ ] SUBPLAN updated with learnings
- [ ] EXECUTION_TASK completed
- [ ] README updated (if interface changed)
- [ ] Migration guide created (if breaking changes)

### Performance Gates

- [ ] No performance regressions
- [ ] Batch operations used for bulk data
- [ ] Database queries optimized
- [ ] Memory usage acceptable
- [ ] Profiling done (if performance-critical)

### Integration Gates

- [ ] Backward compatible (or migration path provided)
- [ ] Feature flags in place (if needed)
- [ ] Can run in parallel with old code
- [ ] Rollback procedure documented
- [ ] Team reviewed and approved

---

## üö® Common Pitfalls and How to Avoid Them

### Pitfall 1: Big Bang Refactor

**Problem**: Trying to refactor everything at once
**Result**: Huge PR, merge conflicts, hard to review, risky deployment

**Solution**: Implement one achievement at a time
- Create small, focused PRs
- Merge frequently to feature branch
- Deploy incrementally with feature flags

### Pitfall 2: Breaking Backward Compatibility

**Problem**: Changing interfaces without migration path
**Result**: All stages break, pipeline fails, emergency rollback

**Solution**: Always maintain compatibility
- Implement new code alongside old
- Use adapters/wrappers for interface changes
- Provide gradual migration path
- Keep old code working during transition

### Pitfall 3: Insufficient Testing

**Problem**: Assuming refactored code works without tests
**Result**: Bugs discovered in production (just like validation phase!)

**Solution**: TDD workflow
- Write tests first (define expected behavior)
- Test concurrent scenarios
- Test error cases
- Run full test suite before merging

### Pitfall 4: Ignoring Type Errors

**Problem**: Adding `# type: ignore` to silence mypy
**Result**: Type system doesn't catch bugs (defeats the purpose!)

**Solution**: Fix type errors properly
- Define proper types (TypedDict, Optional, etc.)
- Handle None cases explicitly
- Use type narrowing (isinstance checks)
- Never add `# type: ignore` without understanding why

### Pitfall 5: Copy-Paste Migrations

**Problem**: Copying code from one stage to others without understanding
**Result**: Copying bugs, missing stage-specific logic

**Solution**: Understand before migrating
- Read the code you're refactoring
- Understand what it does
- Identify stage-specific vs common code
- Test each migration individually

---

## üìä Progress Tracking

### Daily Checklist

At end of each work session:

- [ ] EXECUTION_TASK updated with iteration
- [ ] Tests passing (green)
- [ ] Changes committed to branch
- [ ] Next steps documented
- [ ] Blockers identified (if any)

### Achievement Completion Checklist

Before marking achievement complete:

- [ ] All deliverables created
- [ ] All tests passing
- [ ] Documentation updated
- [ ] Code reviewed
- [ ] PR merged
- [ ] EXECUTION_TASK marked complete
- [ ] SUBPLAN archived

### Plan Progress Dashboard

Track overall progress:

```
Priority 0 (Foundation): [==------] 33% (1/3)
Priority 1 (Type Safety): [--------] 0% (0/3)
Priority 2 (Libraries): [--------] 0% (0/6)
Priority 3 (Architecture): [--------] 0% (0/3)
Priority 4 (Orchestration): [--------] 0% (0/3)
Priority 5 (DI): [--------] 0% (0/3)
Priority 6 (Feature Flags): [--------] 0% (0/2)

Overall: [=-------] 4% (1/24)
Time Spent: 3h / 67h estimated
```

---

## üéì Key Success Factors

### What Makes Refactoring Successful

1. **Clear Motivation**: Every change prevents real bugs (validation proof)
2. **Small Steps**: One achievement at a time, merge frequently
3. **Test Coverage**: TDD workflow prevents regressions
4. **Type Safety**: Catch bugs at dev time, not runtime
5. **Team Buy-In**: Everyone understands why and how

### What Makes Refactoring Fail

1. **No Clear Goal**: Refactoring for refactoring's sake
2. **Big Bang Approach**: Try to change everything at once
3. **No Tests**: Hope it works, discover it doesn't
4. **Breaking Changes**: No migration path, breaks everything
5. **Poor Communication**: Team doesn't understand changes

### How This Refactor Is Set Up for Success

‚úÖ **Clear Motivation**: 9 real bugs from validation phase  
‚úÖ **Small Steps**: 24 achievements, merge each individually  
‚úÖ **Test Coverage**: TDD required for every achievement  
‚úÖ **Type Safety**: mypy strict mode enforced  
‚úÖ **Team Buy-In**: Documentation explains why each change matters  

---

## üìö Additional Resources

### Documents to Reference

**Strategic Context**:
- EXECUTION_ANALYSIS_THREE-PLAN-INTEGRATION-STRATEGY.md (why these three plans connect)
- EXECUTION_ANALYSIS_VALIDATION-LEARNINGS-SYNTHESIS.md (what validation taught us)

**Technical Details**:
- EXECUTION_CASE-STUDY_OBSERVABILITY-VALIDATION-LEARNINGS.md (all 9 bugs analyzed)
- PLAN_STAGE-DOMAIN-REFACTOR.md (all 24 achievements)

**Methodology**:
- LLM-METHODOLOGY.md (overall approach)
- LLM/guides/SUBPLAN-WORKFLOW-GUIDE.md (how to create SUBPLANs)
- LLM/guides/EXECUTION-TAXONOMY.md (work types)

### Templates to Use

- LLM/templates/SUBPLAN-TEMPLATE.md
- LLM/templates/EXECUTION_TASK-TEMPLATE.md
- LLM/templates/TEST-TEMPLATE.py

### Commands to Remember

```bash
# Run tests
pytest tests/ -v

# Type checking
mypy --strict business/stages/

# Find duplicated code
grep -r "pattern" business/stages/graphrag/

# Create branch
git checkout -b refactor/achievement-X.Y

# Run single test file
pytest tests/path/to/test_file.py -v

# Check test coverage
pytest --cov=business/stages --cov-report=html
```

---

## üéØ Final Checklist: Are You Ready to Start?

Before beginning implementation:

- [ ] Read EXECUTION_ANALYSIS_VALIDATION-LEARNINGS-SYNTHESIS.md
- [ ] Read EXECUTION_CASE-STUDY_OBSERVABILITY-VALIDATION-LEARNINGS.md
- [ ] Understand which bugs your achievement prevents
- [ ] Reviewed the specific achievement in PLAN
- [ ] Identified starting priority (Tier 1 recommended)
- [ ] Environment set up (pytest, mypy installed)
- [ ] Know how to create SUBPLAN and EXECUTION_TASK
- [ ] Understand TDD workflow
- [ ] Ready to write tests first!

**If all checked**: You're ready to start! Begin with Achievement 0.1 (GraphRAGBaseStage).

**If not all checked**: Review this guide and referenced documents until ready.

---

**Document Type**: Implementation Guide  
**Next Steps**: 
1. Pick your starting achievement (recommend 0.1)
2. Create SUBPLAN
3. Follow "Your First Hour" workflow
4. Start implementing!

Good luck! üöÄ






