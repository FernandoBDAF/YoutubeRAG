## ğŸ§± Technical Architecture (Hackathon-scale)

### 1. Data Ingestion Agent

- Uses YouTube API to fetch:
  - metadata (title, channel, publish date, stats, category)
  - transcript (via youtube-transcript-api)
  - thumbnail URL
- Adds derived fields: duration, keywords, engagement score.
- Inserts raw â†’ `mongodb.collection("raw_videos")`.

### 2. Processing / Enrichment Agents

Each step writes to a new collection (demonstrating â€œcontext engineering via structured memoryâ€).

| Agent              | Function                                                                                                                              | MongoDB Collection   |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------- | -------------------- |
| TranscriptCleaner  | Fix punctuation, remove disfluencies, paragraphize using an LLM (Voyage AI embeddings optional for semantic segmentation).            | cleaned_transcripts  |
| SpeakerTagger      | Basic diarization heuristic + LLM inference for speaker roles.                                                                        | enriched_transcripts |
| VisualAnnotator    | Uses Voyage AI Vision or GPT-4 Vision on key frames â†’ adds [visual_context] text snippets.                                            | multimodal_segments  |
| Chunker + Embedder | Splits into semantic chunks (~500 tokens) â†’ creates embeddings with Voyage AI API â†’ stores vectors + metadata in Atlas Vector Search. | video_chunks         |

### 3. Retrieval + Generation Agent (RAG Core)

- Query embedding â†’ Atlas Vector Search â†’ retrieve top-k chunks.
- Compose contextual prompt (system + retrieved content).
- Generate response with LLM (GPT-4 / Voyage LLM).
- Optionally: store query + retrieved chunks + answer back to `memory_logs` for the agentâ€™s long-term memory.

### 4. Interface Layer

Streamlit dashboard showing:

- Filters: channel / topic / date
- Context map: embedding clusters (UMAP)
- Interactive Q&A panel
- â€œMemory growthâ€ timeline (how context expands as new videos are added)

### â˜ï¸ Hackathon-Relevant Stack

| Component         | Tech                        | Why it fits â€œContext Engineeringâ€               |
| ----------------- | --------------------------- | ----------------------------------------------- |
| Persistent memory | MongoDB Atlas Vector Search | Stores long-term semantic memory for agents.    |
| Embeddings        | Voyage AI Embeddings API    | High-quality, compact context representation.   |
| LLM reasoning     | OpenAI / Voyage LLM         | Adaptive agent that learns from stored context. |
| Data ingestion    | YouTube API + Python agents | Demonstrates real-world dynamic data sources.   |
| Visualization     | Streamlit + Plotly          | Shows how context evolves and is retrieved.     |

### ğŸ§  Why Itâ€™s a Strong Hackathon Fit

- Directly addresses â€œpersistent, adaptive agents.â€
- Shows how to capture, store, and recall large external knowledge (YouTube videos).
- Demonstrates context engineering.
- Multiple structured memory layers inside MongoDB: raw â†’ cleaned â†’ enriched â†’ embedded.
- Uses official hackathon partners (Atlas Vector Search + Voyage AI embeddings).
- Visually engaging: Streamlit UI shows context recall and memory expansion.
- Expandable: Same architecture can index podcasts, meetings, or enterprise knowledge.

### ğŸš€ Demo Narrative (7-minute flow)

1. Ingest new YouTube video â€“ show raw JSON entry.
2. Agents run â€“ transcript cleaned, speakers inferred, visuals summarized.
3. MongoDB Atlas UI â€“ display embedded chunks in vector search index.
4. User query: â€œHow has this creatorâ€™s strategy changed over time?â€
5. Live RAG answer: agent retrieves relevant clips + summarizes evolution.
6. Show â€œmemory logâ€ â€“ the agent stores this Q&A for reuse later.
7. Dashboard: updated vector map proving persistent, adaptive memory.

### ğŸ—“ï¸ Week-of-Hackathon Plan

| Day               | Milestone                                                                                                 |
| ----------------- | --------------------------------------------------------------------------------------------------------- |
| D-6 â†’ D-4         | Finalize schema (video_id, chunks, embedding, metadata). Test Atlas Vector Search + Voyage embedding API. |
| D-3 â†’ D-2         | Build Python agents for ingest â†’ clean â†’ embed. Use sample 10 videos.                                     |
| D-1               | Create minimal Streamlit UI + retrieval endpoint.                                                         |
| Hackathon Day 1â€“2 | Integrate Atlas + Voyage credentials; polish demo; prep slides.                                           |
| Final Pitch       | Present live ingestion â†’ question â†’ context-aware answer.                                                 |

### ğŸ“„ Deliverables

- `main.py` â€“ orchestrator (agent pipeline)
- `agents/` â€“ each stage class (cleaner, diarizer, chunker, retriever)
- `streamlit_app.py` â€“ interactive demo
- `mongodb_schema.json` â€“ collections + vector index config
- `README.md` â€“ problem â†’ solution â†’ tech â†’ demo steps
